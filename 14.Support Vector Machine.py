# -*- coding: utf-8 -*-
"""14.Support Vector Machine.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R4U1cRnVjvixCudXKpMnCTtKVu_j3HoM

# **Support Vector Machine**
"""

# importing pandas library
import pandas as pd

"""**Loading Dataset**"""

from sklearn.datasets import load_iris

iris=load_iris()

# dir() is a Python built-in function which lists all the attributes and methods that an object has.
dir(iris)

# getting feature names
iris.feature_names

# making a DataFrame and storing the column=Feature_Names in it
df=pd.DataFrame(iris.data,columns=iris.feature_names)
df.head()

# adding another Column of Target/Output
df['Target'] = iris.target
df.head()

# priting the output
iris.target_names

# priting a specific class
df[df.Target==1].head()

# creating another Column and storing the flower names in it
# Target will give numeric values, this will act as indexes in target_names which gives the acutal values
df['Flower_Name'] = df.Target.apply(lambda x: iris.target_names [x])
df.head()

# importing matplotlib library for plotting
import matplotlib.pyplot as plt

# splitting classes into different Dataframes
df0=df[df.Target==0]
df1=df[df.Target==1]
df2=df[df.Target==2]

"""**Visualization**"""

# priting scatter plot for dataframe 0 and dataframe 1 against sepal length and sepal width
plt.xlabel('sepal length (cm)')
plt.ylabel('sepal width (cm)')
plt.scatter(df0['sepal length (cm)'], df0['sepal width (cm)'], color='green', marker='+')
plt.scatter(df1['sepal length (cm)'], df1['sepal width (cm)'], color='blue', marker='.')

# priting scatter plot for dataframe 0 and dataframe 1 against petal length and petal width
plt.xlabel('petal length (cm)')
plt.ylabel('petal width (cm)')
plt.scatter(df0['petal length (cm)'], df0['petal width (cm)'], color='green', marker='+')
plt.scatter(df1['petal length (cm)'], df1['petal width (cm)'], color='blue', marker='.')

"""**Model Training**

"""

from sklearn.model_selection import train_test_split

# Creating input variable by dropping the target variable from the dataframe
X= df.drop(['Target','Flower_Name'], axis=1)
X.head()

# storing the target in the y variable
Y=df.Target
Y.head()

"""**Train-Test Split**"""

x_train, x_test, y_train, y_test= train_test_split(X,Y, test_size=0.2)

len(x_train)

len(x_test)

"""SVC = Support Vector Classification.<br>

It’s scikit-learn’s implementation of Support Vector Machine (SVM) for classification tasks.<br>

Comes from the svm module of sklearn. <br>

"""

from sklearn.svm import SVC

"""**Kernel**='linear' tells the SVM to use a linear kernel → the decision boundary will be a straight line (or hyperplane). <br>


**C=10** → Regularization parameter.
Larger C means the model tries harder to classify all training points correctly, even if it makes the margin smaller and more complex. <br>

**gamma** = controls boundary shape/curviness.<br>

kernel = what kind of curve/line to draw.<br>

gamma = how wide or narrow the curve bends around points.
"""

model=SVC(C=10,gamma=30, kernel='linear')

model.fit(x_train,y_train)

# testing accuracy
model.score(x_test,y_test)

