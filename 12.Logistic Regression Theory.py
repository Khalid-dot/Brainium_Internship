# -*- coding: utf-8 -*-
"""12.Logistic Regression Theory.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VU4bhotbkE4QinYGxhClxOxpcaWNLxFP

# **Logistic Regression Theory**
"""

# importing libraries
import pandas as pd
import matplotlib.pyplot as plt

df=pd.read_csv('/content/insurance_data.csv')
df

"""### **Visualization**"""

# ploting a scatter plot for the dataset
plt.scatter(df.age,df.bought_insurance,marker='+',color='red')

"""### **Model Training**"""

# importing model selection library from scikit learn
from sklearn.model_selection import train_test_split

"""df['age'], df.age → gives a Series (shape (n,) = 1D).<br>
df[['age']] → gives a DataFrame (shape (n,1) = 2D).<br>
Machine learning models in sklearn expect 2D features: (n_samples, n_features).<br>
"""

# spliting training, testing
x_train,x_test,y_train,y_test=train_test_split(df[['age']],df.bought_insurance,test_size=0.1)

x_train

# importing Logistic Regression for data training
from sklearn.linear_model import LogisticRegression

model= LogisticRegression()

# training
model.fit(x_train,y_train)

# making predictions on the testing data
model.predict(x_test)

# checking for accuracy
model.score(x_test,y_test)

x_test

"""Instead of predicting the class label (0 or 1), it predicts the probability of each class for every sample in x_test, before comma is the probability for 0 and after comma is the probability for 1.


"""

model.predict_proba(x_test)

# predicting for another data sample
model.predict([[55]])

model.predict([[25]])