# -*- coding: utf-8 -*-
"""Week-7 Proj-Model_selection_&_Evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/193BFAxbLA60te8ktEUWwmczPIo4zxHlQ

# **Week 7 Project: Model Selection & Evaluation**
"""

# importing libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, auc, classification_report,precision_recall_curve,confusion_matrix #for plotting curves
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.datasets import load_breast_cancer

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

data = load_breast_cancer()
x, y = data.data, data.target
print("Feature shape:", x.shape)
print("Target classes:", np.unique(y))

# for testing
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42, stratify=y)

# for validation
x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.125,random_state=42, stratify=y_train)

print("Train size:", x_train.shape)
print("Validation size:", x_val.shape)
print("Test size:", x_test.shape)

# loading Logistic Regression
model=LogisticRegression(max_iter=10000)

# model training
model.fit(x_train,y_train)

y_test_pred=model.predict(x_test)
y_val_pred=model.predict(x_val)

"""**Validation Classification**"""

print("Validation Classification Report:\n",classification_report(y_val,y_val_pred))

# predict probabilities, take all rows but only the last column
y_val_prob=model.predict_proba(x_val)[:, -1]

# _ represents the threshold here
fpr,tpr,_=roc_curve(y_val,y_val_prob)

roc_auc=auc(fpr,tpr)

"""**ROC Curve Plotting**"""

plt.figure()
plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.3f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Validation Set')
plt.legend(loc='lower right')
plt.show()

precision,recall,_= precision_recall_curve(y_val,y_val_prob)

"""**Precision-Recall Curve Plotting**"""

plt.figure()
plt.plot(recall, precision, color='green')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.show()

"""**CV Scores**"""

cv_roc_scores=cross_val_score(model,x,y,cv=5,scoring='roc_auc')
print("AUC score for each split:",cv_roc_scores)
print("Average AUC:",cv_roc_scores.mean())

"""**Actual AUC Score**"""

y_test_prob=model.predict_proba(x_test)[:,-1]
test_fpr,test_tpr,_=roc_curve(y_test,y_test_prob)
test_auc=auc(test_fpr,test_tpr)
print("Final Test AUC:",test_auc)

