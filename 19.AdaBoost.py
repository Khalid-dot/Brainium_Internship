# -*- coding: utf-8 -*-
"""19.AdaBoost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XVV2nIVyduLW67nOvEdCIO3au4t7cfs4

# **AdaBoost**
"""

# importing basic libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# importing scikit learn libraries
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score

data=pd.read_csv("/content/HR Employee Attrition.csv")
data.head()

le=LabelEncoder()

# performing label encoding
for col in data.select_dtypes(include=["object"]).columns:
  data[col]=le.fit_transform(data[col])

# counting values in the Attrition column
print(data['Attrition'].value_counts())

no=data[data['Attrition']==0]
yes=data[data['Attrition']==1]

"""## **Resampling**"""

# resampling data because of unbalance
from sklearn.utils import resample

# performing Resampling
resample_yes = resample(
    yes,
    replace=True,
    n_samples=len(no),
    random_state=42
)

data=pd.concat([no,resample_yes])

# counting values in the Attrition column
print(data['Attrition'].value_counts())

x=data.drop("Attrition",axis=1)
y=data["Attrition"]

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)

scale=StandardScaler()

# scaling the training and testing data
x_train=scale.fit_transform(x_train)
x_test=scale.transform(x_test)

"""## **Training with AdaBoost**"""

ada=AdaBoostClassifier(
    estimator=DecisionTreeClassifier(max_depth=1),
    n_estimators=100, #number of decision trees involved
    learning_rate=0.5, #decides how big or small weight of the prediction should be. (if α=0.8, and LR is 0.5, then α becomes 0.4)
    random_state=42
)

ada.fit(x_train,y_train)

y_pred=ada.predict(x_test)

acc=accuracy_score(y_test,y_pred)

print("-----------------AdaBoost Results-----------------\n")
print("Accuracy:",acc)
print("\nClassification Report:\n",classification_report(y_test,y_pred))
print("Confusion Matrix:\n",confusion_matrix(y_test,y_pred))

"""## **HyperParameter Tuning**"""

param = {
    "n_estimators":[50,100,200],
    "learning_rate":[0.01,0.1,0.5,0.8],
    "estimator": [DecisionTreeClassifier(max_depth=1),
                 DecisionTreeClassifier(max_depth=2)]
}

grid=GridSearchCV(
    AdaBoostClassifier(random_state=42),
    param,
    scoring="f1",
    cv=5,
    n_jobs=-1 #number of CPUs
)

grid.fit(x_train,y_train)

hp_score=grid.best_score_
print("Best Parameters:",grid.best_params_)
print("Best Score:",hp_score)

print("Accuracy Before HyperParameter Tuning:",acc)
print("Accuracy After HyperParameter Tuning:",hp_score)

"""## **Visualization**"""

features=x.columns
importance=ada.feature_importances_

plt.figure(figsize=(10,10))
plt.barh(features,importance) #horizontal bar plot
plt.xlabel=("Features")
plt.ylabel=("Importance")
plt.title=("AdaBoost Feature Importance")
plt.show()

